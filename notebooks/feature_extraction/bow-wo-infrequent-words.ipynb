{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data with all stop words removed\n",
    "roughDat= pd.read_csv(\"../../data/raw/Emergent_NAACL2016/emergent/url-versions-2015-06-14-clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights into bag of words\n",
    "The BOW model only considers if a known word occurs in a document or not. It does not care about meaning, context, and order in which they appear.\n",
    "This gives the insight that similar documents will have word counts similar to each other. In other words, the more similar the words in two documents, the more similar the documents can be.\n",
    "Limitations of BOW\n",
    "Semantic meaning: the basic BOW approach does not consider the meaning of the word in the document. It completely ignores the context in which itâ€™s used. The same word can be used in multiple places based on the context or nearby words.\n",
    "Vector size: For a large document, the vector size can be huge resulting in a lot of computation and time. You may need to ignore words based on relevance to your use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "#vectorizer = CountVectorizer()\n",
    "allsentences=list(roughDat['articleHeadline'])\n",
    "X = vectorizer.fit_transform(allsentences).toarray()\n",
    "\n",
    "#f we want to convert our occurences to frequencies\n",
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X)\n",
    "# X = tf_transformer.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = frequency.argsort()[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "BowF = X[:, np.concatenate([top, bottom])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(roughDat[[\"articleId\"]],BowF, axis=1)\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df.rename(columns={0: \"articleId\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/processed/features/headline_BoW_wo_infreq.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

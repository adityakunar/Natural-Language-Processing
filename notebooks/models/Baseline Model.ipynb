{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train = pd.read_csv('../../data/raw/Emergent_NAACL2016/emergent/url-versions-2015-06-14-clean-train.csv')\n",
    "train.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "test = pd.read_csv('../../data/raw/Emergent_NAACL2016/emergent/url-versions-2015-06-14-clean-test.csv')\n",
    "test.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features\n",
    "align_feature = pd.read_csv('../../data/processed/features/alignment_feature.csv')\n",
    "cosine_feature = pd.read_csv('../../data/processed/features/cosine_feature.csv')\n",
    "bow_feature = pd.read_csv('../../data/processed/features/headline_BoW.csv')\n",
    "qmark_feature = pd.read_csv('../../data/processed/features/headline_Qmark.csv')\n",
    "neg_alignment_feature = pd.read_csv('../../data/processed/features/neg_alignment_feature.csv')\n",
    "root_dist_feature = pd.read_csv('../../data/processed/features/root_dist_min.csv')\n",
    "svo_feature = pd.read_csv('../../data/processed/features/svo_Lexical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {\"for\": 0, \"observing\": 1, \"against\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace({\"articleHeadlineStance\": target_map})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.replace({\"articleHeadlineStance\": target_map})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    992\n",
       " 1    775\n",
       " 2    304\n",
       " Name: articleHeadlineStance, dtype: int64,\n",
       " 0    246\n",
       " 1    187\n",
       " 2     91\n",
       " Name: articleHeadlineStance, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"articleHeadlineStance\"].value_counts(),test[\"articleHeadlineStance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, align_feature, on=\"articleId\")\n",
    "train = pd.merge(train, cosine_feature, on=\"articleId\")\n",
    "train = pd.merge(train, bow_feature, on=\"articleId\")\n",
    "train = pd.merge(train, qmark_feature, on=\"articleId\")\n",
    "train = pd.merge(train, neg_alignment_feature, on=\"articleId\")\n",
    "train = pd.merge(train, root_dist_feature, on=\"articleId\")\n",
    "train = pd.merge(train, svo_feature, on=\"articleId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test, align_feature, on=\"articleId\")\n",
    "test = pd.merge(test, cosine_feature, on=\"articleId\")\n",
    "test = pd.merge(test, bow_feature, on=\"articleId\")\n",
    "test = pd.merge(test, qmark_feature, on=\"articleId\")\n",
    "test = pd.merge(test, neg_alignment_feature, on=\"articleId\")\n",
    "test = pd.merge(test, root_dist_feature, on=\"articleId\")\n",
    "test = pd.merge(test, svo_feature, on=\"articleId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"articleHeadlineStance\"] = train[\"articleHeadlineStance\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"articleHeadlineStance\"] = test[\"articleHeadlineStance\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets and shuuffle with random seed\n",
    "seed = 1234\n",
    "\n",
    "train = sklearn.utils.shuffle(train, random_state=seed)\n",
    "test = sklearn.utils.shuffle(test, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test\n",
    "\n",
    "X_train = train.to_numpy()[:,5:]\n",
    "Y_train = train[\"articleHeadlineStance\"].values.reshape((-1,))\n",
    "\n",
    "X_test = test.to_numpy()[:,5:]\n",
    "Y_test = test[\"articleHeadlineStance\"].values.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.astype(int)\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_test = Y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 524 points : 148\n",
      "Accuracy on test set: 0.7175572519083969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[225,  20,   1],\n",
       "       [ 79, 100,   8],\n",
       "       [ 24,  16,  51]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 10e2\n",
    "C=1\n",
    "penalty='l1'\n",
    "\n",
    "# Normal Train and Test\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty=penalty, C=C, max_iter = max_iter, multi_class='auto', solver=\"liblinear\")\n",
    "ypred = model.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != ypred).sum()))\n",
    "print(\"Accuracy on test set: \"+str(model.score(X_test,y_test)))\n",
    "confusion_matrix(y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
